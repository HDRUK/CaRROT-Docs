{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bored-communist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: carrot run py [OPTIONS] COMMAND [ARGS]...\r\n",
      "\r\n",
      "  Commands for using python configurations to run the ETL transformation.\r\n",
      "\r\n",
      "Options:\r\n",
      "  --help  Show this message and exit.\r\n",
      "\r\n",
      "Commands:\r\n",
      "  list      List all the python classes there are available to run\r\n",
      "  make      Generate a python class from the OMOP mapping json\r\n",
      "  map       Perform OMOP Mapping given a python configuration file.\r\n",
      "  register  Register a python class with the tool\r\n",
      "  remove    remove a registered class\r\n"
     ]
    }
   ],
   "source": [
    "!carrot run py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "following-browse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recreating file /Users/calummacdonald/Usher/CO-CONNECT/docs/docs/CaRROT-CDM/notebooks/ExampleDataset.py\r\n"
     ]
    }
   ],
   "source": [
    "!carrot run py make --name ExampleDataset ../data/rules.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-trustee",
   "metadata": {},
   "source": [
    "This automatically creates a file that looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "meaning-spice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ExampleDataset.py\n",
    "from carrot.cdm import define_person, define_condition_occurrence, define_visit_occurrence, define_measurement, define_observation, define_drug_exposure\n",
    "from carrot.cdm import CommonDataModel\n",
    "import json\n",
    "\n",
    "class ExampleDataset(CommonDataModel):\n",
    "    \n",
    "    def __init__(self,**kwargs):\n",
    "        \"\"\" \n",
    "        initialise the inputs and setup indexing \n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    \n",
    "    @define_person\n",
    "    def person_0(self):\n",
    "        \"\"\"\n",
    "        Create CDM object for person\n",
    "        \"\"\"\n",
    "        self.birth_datetime.series = self.inputs[\"Demographics.csv\"][\"Age\"]\n",
    "        self.gender_concept_id.series = self.inputs[\"Demographics.csv\"][\"Sex\"]\n",
    "        self.gender_source_concept_id.series = self.inputs[\"Demographics.csv\"][\"Sex\"]\n",
    "        self.gender_source_value.series = self.inputs[\"Demographics.csv\"][\"Sex\"]\n",
    "        self.person_id.series = self.inputs[\"Demographics.csv\"][\"ID\"]\n",
    "        \n",
    "        # --- insert field operations --- \n",
    "        self.birth_datetime.series = self.tools.get_datetime_from_age(self.birth_datetime.series)\n",
    "        \n",
    "        # --- insert term mapping --- \n",
    "        self.gender_concept_id.series = self.gender_concept_id.series.map(\n",
    "            {\n",
    "                \"Male\": 8507\n",
    "            }\n",
    "        )\n",
    "        self.gender_source_concept_id.series = self.gender_source_concept_id.series.map(\n",
    "            {\n",
    "                \"Male\": 8507\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    @define_person\n",
    "    def person_1(self):\n",
    "        \"\"\"\n",
    "        Create CDM object for person\n",
    "        \"\"\"\n",
    "        self.birth_datetime.series = self.inputs[\"Demographics.csv\"][\"Age\"]\n",
    "        self.gender_concept_id.series = self.inputs[\"Demographics.csv\"][\"Sex\"]\n",
    "        self.gender_source_concept_id.series = self.inputs[\"Demographics.csv\"][\"Sex\"]\n",
    "        self.gender_source_value.series = self.inputs[\"Demographics.csv\"][\"Sex\"]\n",
    "        self.person_id.series = self.inputs[\"Demographics.csv\"][\"ID\"]\n",
    "        \n",
    "        # --- insert field operations --- \n",
    "        self.birth_datetime.series = self.tools.get_datetime_from_age(self.birth_datetime.series)\n",
    "        \n",
    "        # --- insert term mapping --- \n",
    "        self.gender_concept_id.series = self.gender_concept_id.series.map(\n",
    "            {\n",
    "                \"Female\": 8532\n",
    "            }\n",
    "        )\n",
    "        self.gender_source_concept_id.series = self.gender_source_concept_id.series.map(\n",
    "            {\n",
    "                \"Female\": 8532\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    @define_observation\n",
    "    def observation_0(self):\n",
    "        \"\"\"\n",
    "        Create CDM object for observation\n",
    "        \"\"\"\n",
    "        self.observation_concept_id.series = self.inputs[\"Serology.csv\"][\"IgG\"]\n",
    "        self.observation_datetime.series = self.inputs[\"Serology.csv\"][\"Date\"]\n",
    "        self.observation_source_concept_id.series = self.inputs[\"Serology.csv\"][\"IgG\"]\n",
    "        self.observation_source_value.series = self.inputs[\"Serology.csv\"][\"IgG\"]\n",
    "        self.person_id.series = self.inputs[\"Serology.csv\"][\"ID\"]\n",
    "        \n",
    "        # --- insert field operations --- \n",
    "        \n",
    "        # --- insert term mapping --- \n",
    "        self.observation_concept_id.series = self.tools.make_scalar(self.observation_concept_id.series,4288455)\n",
    "        self.observation_source_concept_id.series = self.tools.make_scalar(self.observation_source_concept_id.series,4288455)\n",
    "        \n",
    "    @define_observation\n",
    "    def observation_1(self):\n",
    "        \"\"\"\n",
    "        Create CDM object for observation\n",
    "        \"\"\"\n",
    "        self.observation_concept_id.series = self.inputs[\"Hospital_Visit.csv\"][\"reason\"]\n",
    "        self.observation_datetime.series = self.inputs[\"Hospital_Visit.csv\"][\"admission_date\"]\n",
    "        self.observation_source_concept_id.series = self.inputs[\"Hospital_Visit.csv\"][\"reason\"]\n",
    "        self.observation_source_value.series = self.inputs[\"Hospital_Visit.csv\"][\"reason\"]\n",
    "        self.person_id.series = self.inputs[\"Hospital_Visit.csv\"][\"ID\"]\n",
    "        \n",
    "        # --- insert field operations --- \n",
    "        \n",
    "        # --- insert term mapping --- \n",
    "        self.observation_concept_id.series = self.observation_concept_id.series.map(\n",
    "            {\n",
    "                \"Heart Attack\": 4059317\n",
    "            }\n",
    "        )\n",
    "        self.observation_source_concept_id.series = self.observation_source_concept_id.series.map(\n",
    "            {\n",
    "                \"Heart Attack\": 4059317\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    @define_observation\n",
    "    def observation_2(self):\n",
    "        \"\"\"\n",
    "        Create CDM object for observation\n",
    "        \"\"\"\n",
    "        self.observation_concept_id.series = self.inputs[\"Hospital_Visit.csv\"][\"reason\"]\n",
    "        self.observation_datetime.series = self.inputs[\"Hospital_Visit.csv\"][\"admission_date\"]\n",
    "        self.observation_source_concept_id.series = self.inputs[\"Hospital_Visit.csv\"][\"reason\"]\n",
    "        self.observation_source_value.series = self.inputs[\"Hospital_Visit.csv\"][\"reason\"]\n",
    "        self.person_id.series = self.inputs[\"Hospital_Visit.csv\"][\"ID\"]\n",
    "        \n",
    "        # --- insert field operations --- \n",
    "        \n",
    "        # --- insert term mapping --- \n",
    "        self.observation_concept_id.series = self.observation_concept_id.series.map(\n",
    "            {\n",
    "                \"COVID-19\": 37311065\n",
    "            }\n",
    "        )\n",
    "        self.observation_source_concept_id.series = self.observation_source_concept_id.series.map(\n",
    "            {\n",
    "                \"COVID-19\": 37311065\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    @define_observation\n",
    "    def observation_3(self):\n",
    "        \"\"\"\n",
    "        Create CDM object for observation\n",
    "        \"\"\"\n",
    "        self.observation_concept_id.series = self.inputs[\"Hospital_Visit.csv\"][\"reason\"]\n",
    "        self.observation_datetime.series = self.inputs[\"Hospital_Visit.csv\"][\"admission_date\"]\n",
    "        self.observation_source_concept_id.series = self.inputs[\"Hospital_Visit.csv\"][\"reason\"]\n",
    "        self.observation_source_value.series = self.inputs[\"Hospital_Visit.csv\"][\"reason\"]\n",
    "        self.person_id.series = self.inputs[\"Hospital_Visit.csv\"][\"ID\"]\n",
    "        \n",
    "        # --- insert field operations --- \n",
    "        \n",
    "        # --- insert term mapping --- \n",
    "        self.observation_concept_id.series = self.observation_concept_id.series.map(\n",
    "            {\n",
    "                \"Cancer\": 40757663\n",
    "            }\n",
    "        )\n",
    "        self.observation_source_concept_id.series = self.observation_source_concept_id.series.map(\n",
    "            {\n",
    "                \"Cancer\": 40757663\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    @define_condition_occurrence\n",
    "    def condition_occurrence_0(self):\n",
    "        \"\"\"\n",
    "        Create CDM object for condition_occurrence\n",
    "        \"\"\"\n",
    "        self.condition_concept_id.series = self.inputs[\"Symptoms.csv\"][\"Headache\"]\n",
    "        self.condition_end_datetime.series = self.inputs[\"Symptoms.csv\"][\"date_occurrence\"]\n",
    "        self.condition_source_concept_id.series = self.inputs[\"Symptoms.csv\"][\"Headache\"]\n",
    "        self.condition_source_value.series = self.inputs[\"Symptoms.csv\"][\"Headache\"]\n",
    "        self.condition_start_datetime.series = self.inputs[\"Symptoms.csv\"][\"date_occurrence\"]\n",
    "        self.person_id.series = self.inputs[\"Symptoms.csv\"][\"ID\"]\n",
    "        \n",
    "        # --- insert field operations --- \n",
    "        \n",
    "        # --- insert term mapping --- \n",
    "        self.condition_concept_id.series = self.condition_concept_id.series.map(\n",
    "            {\n",
    "                \"Yes\": 378253\n",
    "            }\n",
    "        )\n",
    "        self.condition_source_concept_id.series = self.condition_source_concept_id.series.map(\n",
    "            {\n",
    "                \"Yes\": 378253\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    @define_condition_occurrence\n",
    "    def condition_occurrence_1(self):\n",
    "        \"\"\"\n",
    "        Create CDM object for condition_occurrence\n",
    "        \"\"\"\n",
    "        self.condition_concept_id.series = self.inputs[\"Symptoms.csv\"][\"Fatigue\"]\n",
    "        self.condition_end_datetime.series = self.inputs[\"Symptoms.csv\"][\"date_occurrence\"]\n",
    "        self.condition_source_concept_id.series = self.inputs[\"Symptoms.csv\"][\"Fatigue\"]\n",
    "        self.condition_source_value.series = self.inputs[\"Symptoms.csv\"][\"Fatigue\"]\n",
    "        self.condition_start_datetime.series = self.inputs[\"Symptoms.csv\"][\"date_occurrence\"]\n",
    "        self.person_id.series = self.inputs[\"Symptoms.csv\"][\"ID\"]\n",
    "        \n",
    "        # --- insert field operations --- \n",
    "        \n",
    "        # --- insert term mapping --- \n",
    "        self.condition_concept_id.series = self.condition_concept_id.series.map(\n",
    "            {\n",
    "                \"Yes\": 4223659\n",
    "            }\n",
    "        )\n",
    "        self.condition_source_concept_id.series = self.condition_source_concept_id.series.map(\n",
    "            {\n",
    "                \"Yes\": 4223659\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    @define_condition_occurrence\n",
    "    def condition_occurrence_2(self):\n",
    "        \"\"\"\n",
    "        Create CDM object for condition_occurrence\n",
    "        \"\"\"\n",
    "        self.condition_concept_id.series = self.inputs[\"Symptoms.csv\"][\"Dizzy\"]\n",
    "        self.condition_end_datetime.series = self.inputs[\"Symptoms.csv\"][\"date_occurrence\"]\n",
    "        self.condition_source_concept_id.series = self.inputs[\"Symptoms.csv\"][\"Dizzy\"]\n",
    "        self.condition_source_value.series = self.inputs[\"Symptoms.csv\"][\"Dizzy\"]\n",
    "        self.condition_start_datetime.series = self.inputs[\"Symptoms.csv\"][\"date_occurrence\"]\n",
    "        self.person_id.series = self.inputs[\"Symptoms.csv\"][\"ID\"]\n",
    "        \n",
    "        # --- insert field operations --- \n",
    "        \n",
    "        # --- insert term mapping --- \n",
    "        self.condition_concept_id.series = self.condition_concept_id.series.map(\n",
    "            {\n",
    "                \"Yes\": 4223938\n",
    "            }\n",
    "        )\n",
    "        self.condition_source_concept_id.series = self.condition_source_concept_id.series.map(\n",
    "            {\n",
    "                \"Yes\": 4223938\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    @define_condition_occurrence\n",
    "    def condition_occurrence_3(self):\n",
    "        \"\"\"\n",
    "        Create CDM object for condition_occurrence\n",
    "        \"\"\"\n",
    "        self.condition_concept_id.series = self.inputs[\"Symptoms.csv\"][\"Cough\"]\n",
    "        self.condition_end_datetime.series = self.inputs[\"Symptoms.csv\"][\"date_occurrence\"]\n",
    "        self.condition_source_concept_id.series = self.inputs[\"Symptoms.csv\"][\"Cough\"]\n",
    "        self.condition_source_value.series = self.inputs[\"Symptoms.csv\"][\"Cough\"]\n",
    "        self.condition_start_datetime.series = self.inputs[\"Symptoms.csv\"][\"date_occurrence\"]\n",
    "        self.person_id.series = self.inputs[\"Symptoms.csv\"][\"ID\"]\n",
    "        \n",
    "        # --- insert field operations --- \n",
    "        \n",
    "        # --- insert term mapping --- \n",
    "        self.condition_concept_id.series = self.condition_concept_id.series.map(\n",
    "            {\n",
    "                \"Yes\": 254761\n",
    "            }\n",
    "        )\n",
    "        self.condition_source_concept_id.series = self.condition_source_concept_id.series.map(\n",
    "            {\n",
    "                \"Yes\": 254761\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    @define_condition_occurrence\n",
    "    def condition_occurrence_4(self):\n",
    "        \"\"\"\n",
    "        Create CDM object for condition_occurrence\n",
    "        \"\"\"\n",
    "        self.condition_concept_id.series = self.inputs[\"Symptoms.csv\"][\"Fever\"]\n",
    "        self.condition_end_datetime.series = self.inputs[\"Symptoms.csv\"][\"date_occurrence\"]\n",
    "        self.condition_source_concept_id.series = self.inputs[\"Symptoms.csv\"][\"Fever\"]\n",
    "        self.condition_source_value.series = self.inputs[\"Symptoms.csv\"][\"Fever\"]\n",
    "        self.condition_start_datetime.series = self.inputs[\"Symptoms.csv\"][\"date_occurrence\"]\n",
    "        self.person_id.series = self.inputs[\"Symptoms.csv\"][\"ID\"]\n",
    "        \n",
    "        # --- insert field operations --- \n",
    "        \n",
    "        # --- insert term mapping --- \n",
    "        self.condition_concept_id.series = self.condition_concept_id.series.map(\n",
    "            {\n",
    "                \"Yes\": 437663\n",
    "            }\n",
    "        )\n",
    "        self.condition_source_concept_id.series = self.condition_source_concept_id.series.map(\n",
    "            {\n",
    "                \"Yes\": 437663\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    @define_condition_occurrence\n",
    "    def condition_occurrence_5(self):\n",
    "        \"\"\"\n",
    "        Create CDM object for condition_occurrence\n",
    "        \"\"\"\n",
    "        self.condition_concept_id.series = self.inputs[\"Symptoms.csv\"][\"Muscle_Pain\"]\n",
    "        self.condition_end_datetime.series = self.inputs[\"Symptoms.csv\"][\"date_occurrence\"]\n",
    "        self.condition_source_concept_id.series = self.inputs[\"Symptoms.csv\"][\"Muscle_Pain\"]\n",
    "        self.condition_source_value.series = self.inputs[\"Symptoms.csv\"][\"Muscle_Pain\"]\n",
    "        self.condition_start_datetime.series = self.inputs[\"Symptoms.csv\"][\"date_occurrence\"]\n",
    "        self.person_id.series = self.inputs[\"Symptoms.csv\"][\"ID\"]\n",
    "        \n",
    "        # --- insert field operations --- \n",
    "        \n",
    "        # --- insert term mapping --- \n",
    "        self.condition_concept_id.series = self.condition_concept_id.series.map(\n",
    "            {\n",
    "                \"Yes\": 442752\n",
    "            }\n",
    "        )\n",
    "        self.condition_source_concept_id.series = self.condition_source_concept_id.series.map(\n",
    "            {\n",
    "                \"Yes\": 442752\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    @define_condition_occurrence\n",
    "    def condition_occurrence_6(self):\n",
    "        \"\"\"\n",
    "        Create CDM object for condition_occurrence\n",
    "        \"\"\"\n",
    "        self.condition_concept_id.series = self.inputs[\"Hospital_Visit.csv\"][\"reason\"]\n",
    "        self.condition_end_datetime.series = self.inputs[\"Hospital_Visit.csv\"][\"admission_date\"]\n",
    "        self.condition_source_concept_id.series = self.inputs[\"Hospital_Visit.csv\"][\"reason\"]\n",
    "        self.condition_source_value.series = self.inputs[\"Hospital_Visit.csv\"][\"reason\"]\n",
    "        self.condition_start_datetime.series = self.inputs[\"Hospital_Visit.csv\"][\"admission_date\"]\n",
    "        self.person_id.series = self.inputs[\"Hospital_Visit.csv\"][\"ID\"]\n",
    "        \n",
    "        # --- insert field operations --- \n",
    "        \n",
    "        # --- insert term mapping --- \n",
    "        self.condition_concept_id.series = self.condition_concept_id.series.map(\n",
    "            {\n",
    "                \"Pneumonia\": 255848\n",
    "            }\n",
    "        )\n",
    "        self.condition_source_concept_id.series = self.condition_source_concept_id.series.map(\n",
    "            {\n",
    "                \"Pneumonia\": 255848\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    @define_condition_occurrence\n",
    "    def condition_occurrence_7(self):\n",
    "        \"\"\"\n",
    "        Create CDM object for condition_occurrence\n",
    "        \"\"\"\n",
    "        self.condition_concept_id.series = self.inputs[\"GP_Records.csv\"][\"comorbidity\"]\n",
    "        self.condition_end_datetime.series = self.inputs[\"GP_Records.csv\"][\"date_of_visit\"]\n",
    "        self.condition_source_concept_id.series = self.inputs[\"GP_Records.csv\"][\"comorbidity\"]\n",
    "        self.condition_source_value.series = self.inputs[\"GP_Records.csv\"][\"comorbidity\"]\n",
    "        self.condition_start_datetime.series = self.inputs[\"GP_Records.csv\"][\"date_of_visit\"]\n",
    "        self.person_id.series = self.inputs[\"GP_Records.csv\"][\"ID\"]\n",
    "        \n",
    "        # --- insert field operations --- \n",
    "        \n",
    "        # --- insert term mapping --- \n",
    "        self.condition_concept_id.series = self.condition_concept_id.series.map(\n",
    "            {\n",
    "                \"Mental Health\": 4131548\n",
    "            }\n",
    "        )\n",
    "        self.condition_source_concept_id.series = self.condition_source_concept_id.series.map(\n",
    "            {\n",
    "                \"Mental Health\": 4131548\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    @define_condition_occurrence\n",
    "    def condition_occurrence_8(self):\n",
    "        \"\"\"\n",
    "        Create CDM object for condition_occurrence\n",
    "        \"\"\"\n",
    "        self.condition_concept_id.series = self.inputs[\"GP_Records.csv\"][\"comorbidity\"]\n",
    "        self.condition_end_datetime.series = self.inputs[\"GP_Records.csv\"][\"date_of_visit\"]\n",
    "        self.condition_source_concept_id.series = self.inputs[\"GP_Records.csv\"][\"comorbidity\"]\n",
    "        self.condition_source_value.series = self.inputs[\"GP_Records.csv\"][\"comorbidity\"]\n",
    "        self.condition_start_datetime.series = self.inputs[\"GP_Records.csv\"][\"date_of_visit\"]\n",
    "        self.person_id.series = self.inputs[\"GP_Records.csv\"][\"ID\"]\n",
    "        \n",
    "        # --- insert field operations --- \n",
    "        \n",
    "        # --- insert term mapping --- \n",
    "        self.condition_concept_id.series = self.condition_concept_id.series.map(\n",
    "            {\n",
    "                \"Mental Health\": 432586\n",
    "            }\n",
    "        )\n",
    "        self.condition_source_concept_id.series = self.condition_source_concept_id.series.map(\n",
    "            {\n",
    "                \"Mental Health\": 432586\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    @define_condition_occurrence\n",
    "    def condition_occurrence_9(self):\n",
    "        \"\"\"\n",
    "        Create CDM object for condition_occurrence\n",
    "        \"\"\"\n",
    "        self.condition_concept_id.series = self.inputs[\"GP_Records.csv\"][\"comorbidity\"]\n",
    "        self.condition_end_datetime.series = self.inputs[\"GP_Records.csv\"][\"date_of_visit\"]\n",
    "        self.condition_source_concept_id.series = self.inputs[\"GP_Records.csv\"][\"comorbidity\"]\n",
    "        self.condition_source_value.series = self.inputs[\"GP_Records.csv\"][\"comorbidity\"]\n",
    "        self.condition_start_datetime.series = self.inputs[\"GP_Records.csv\"][\"date_of_visit\"]\n",
    "        self.person_id.series = self.inputs[\"GP_Records.csv\"][\"ID\"]\n",
    "        \n",
    "        # --- insert field operations --- \n",
    "        \n",
    "        # --- insert term mapping --- \n",
    "        self.condition_concept_id.series = self.condition_concept_id.series.map(\n",
    "            {\n",
    "                \"Diabetes Type-II\": 201826\n",
    "            }\n",
    "        )\n",
    "        self.condition_source_concept_id.series = self.condition_source_concept_id.series.map(\n",
    "            {\n",
    "                \"Diabetes Type-II\": 201826\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    @define_condition_occurrence\n",
    "    def condition_occurrence_10(self):\n",
    "        \"\"\"\n",
    "        Create CDM object for condition_occurrence\n",
    "        \"\"\"\n",
    "        self.condition_concept_id.series = self.inputs[\"GP_Records.csv\"][\"comorbidity\"]\n",
    "        self.condition_end_datetime.series = self.inputs[\"GP_Records.csv\"][\"date_of_visit\"]\n",
    "        self.condition_source_concept_id.series = self.inputs[\"GP_Records.csv\"][\"comorbidity\"]\n",
    "        self.condition_source_value.series = self.inputs[\"GP_Records.csv\"][\"comorbidity\"]\n",
    "        self.condition_start_datetime.series = self.inputs[\"GP_Records.csv\"][\"date_of_visit\"]\n",
    "        self.person_id.series = self.inputs[\"GP_Records.csv\"][\"ID\"]\n",
    "        \n",
    "        # --- insert field operations --- \n",
    "        \n",
    "        # --- insert term mapping --- \n",
    "        self.condition_concept_id.series = self.condition_concept_id.series.map(\n",
    "            {\n",
    "                \"Heart Condition\": 4185932\n",
    "            }\n",
    "        )\n",
    "        self.condition_source_concept_id.series = self.condition_source_concept_id.series.map(\n",
    "            {\n",
    "                \"Heart Condition\": 4185932\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    @define_condition_occurrence\n",
    "    def condition_occurrence_11(self):\n",
    "        \"\"\"\n",
    "        Create CDM object for condition_occurrence\n",
    "        \"\"\"\n",
    "        self.condition_concept_id.series = self.inputs[\"GP_Records.csv\"][\"comorbidity\"]\n",
    "        self.condition_end_datetime.series = self.inputs[\"GP_Records.csv\"][\"date_of_visit\"]\n",
    "        self.condition_source_concept_id.series = self.inputs[\"GP_Records.csv\"][\"comorbidity\"]\n",
    "        self.condition_source_value.series = self.inputs[\"GP_Records.csv\"][\"comorbidity\"]\n",
    "        self.condition_start_datetime.series = self.inputs[\"GP_Records.csv\"][\"date_of_visit\"]\n",
    "        self.person_id.series = self.inputs[\"GP_Records.csv\"][\"ID\"]\n",
    "        \n",
    "        # --- insert field operations --- \n",
    "        \n",
    "        # --- insert term mapping --- \n",
    "        self.condition_concept_id.series = self.condition_concept_id.series.map(\n",
    "            {\n",
    "                \"High Blood Pressure\": 316866\n",
    "            }\n",
    "        )\n",
    "        self.condition_source_concept_id.series = self.condition_source_concept_id.series.map(\n",
    "            {\n",
    "                \"High Blood Pressure\": 316866\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    @define_drug_exposure\n",
    "    def drug_exposure_0(self):\n",
    "        \"\"\"\n",
    "        Create CDM object for drug_exposure\n",
    "        \"\"\"\n",
    "        self.drug_concept_id.series = self.inputs[\"Vaccinations.csv\"][\"type\"]\n",
    "        self.drug_exposure_end_datetime.series = self.inputs[\"Vaccinations.csv\"][\"date_of_vaccination\"]\n",
    "        self.drug_exposure_start_datetime.series = self.inputs[\"Vaccinations.csv\"][\"date_of_vaccination\"]\n",
    "        self.drug_source_concept_id.series = self.inputs[\"Vaccinations.csv\"][\"type\"]\n",
    "        self.drug_source_value.series = self.inputs[\"Vaccinations.csv\"][\"type\"]\n",
    "        self.person_id.series = self.inputs[\"Vaccinations.csv\"][\"ID\"]\n",
    "        \n",
    "        # --- insert field operations --- \n",
    "        \n",
    "        # --- insert term mapping --- \n",
    "        self.drug_concept_id.series = self.drug_concept_id.series.map(\n",
    "            {\n",
    "                \"Moderna\": 35894915\n",
    "            }\n",
    "        )\n",
    "        self.drug_source_concept_id.series = self.drug_source_concept_id.series.map(\n",
    "            {\n",
    "                \"Moderna\": 35894915\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    @define_drug_exposure\n",
    "    def drug_exposure_1(self):\n",
    "        \"\"\"\n",
    "        Create CDM object for drug_exposure\n",
    "        \"\"\"\n",
    "        self.drug_concept_id.series = self.inputs[\"Vaccinations.csv\"][\"type\"]\n",
    "        self.drug_exposure_end_datetime.series = self.inputs[\"Vaccinations.csv\"][\"date_of_vaccination\"]\n",
    "        self.drug_exposure_start_datetime.series = self.inputs[\"Vaccinations.csv\"][\"date_of_vaccination\"]\n",
    "        self.drug_source_concept_id.series = self.inputs[\"Vaccinations.csv\"][\"type\"]\n",
    "        self.drug_source_value.series = self.inputs[\"Vaccinations.csv\"][\"type\"]\n",
    "        self.person_id.series = self.inputs[\"Vaccinations.csv\"][\"ID\"]\n",
    "        \n",
    "        # --- insert field operations --- \n",
    "        \n",
    "        # --- insert term mapping --- \n",
    "        self.drug_concept_id.series = self.drug_concept_id.series.map(\n",
    "            {\n",
    "                \"AstraZenica\": 35894915\n",
    "            }\n",
    "        )\n",
    "        self.drug_source_concept_id.series = self.drug_source_concept_id.series.map(\n",
    "            {\n",
    "                \"AstraZenica\": 35894915\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    @define_drug_exposure\n",
    "    def drug_exposure_2(self):\n",
    "        \"\"\"\n",
    "        Create CDM object for drug_exposure\n",
    "        \"\"\"\n",
    "        self.drug_concept_id.series = self.inputs[\"Vaccinations.csv\"][\"type\"]\n",
    "        self.drug_exposure_end_datetime.series = self.inputs[\"Vaccinations.csv\"][\"date_of_vaccination\"]\n",
    "        self.drug_exposure_start_datetime.series = self.inputs[\"Vaccinations.csv\"][\"date_of_vaccination\"]\n",
    "        self.drug_source_concept_id.series = self.inputs[\"Vaccinations.csv\"][\"type\"]\n",
    "        self.drug_source_value.series = self.inputs[\"Vaccinations.csv\"][\"type\"]\n",
    "        self.person_id.series = self.inputs[\"Vaccinations.csv\"][\"ID\"]\n",
    "        \n",
    "        # --- insert field operations --- \n",
    "        \n",
    "        # --- insert term mapping --- \n",
    "        self.drug_concept_id.series = self.drug_concept_id.series.map(\n",
    "            {\n",
    "                \"Pfizer\": 35894915\n",
    "            }\n",
    "        )\n",
    "        self.drug_source_concept_id.series = self.drug_source_concept_id.series.map(\n",
    "            {\n",
    "                \"Pfizer\": 35894915\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    @define_drug_exposure\n",
    "    def drug_exposure_3(self):\n",
    "        \"\"\"\n",
    "        Create CDM object for drug_exposure\n",
    "        \"\"\"\n",
    "        self.drug_concept_id.series = self.inputs[\"Vaccinations.csv\"][\"type\"]\n",
    "        self.drug_exposure_end_datetime.series = self.inputs[\"Vaccinations.csv\"][\"date_of_vaccination\"]\n",
    "        self.drug_exposure_start_datetime.series = self.inputs[\"Vaccinations.csv\"][\"date_of_vaccination\"]\n",
    "        self.drug_source_concept_id.series = self.inputs[\"Vaccinations.csv\"][\"type\"]\n",
    "        self.drug_source_value.series = self.inputs[\"Vaccinations.csv\"][\"type\"]\n",
    "        self.person_id.series = self.inputs[\"Vaccinations.csv\"][\"ID\"]\n",
    "        \n",
    "        # --- insert field operations --- \n",
    "        \n",
    "        # --- insert term mapping --- \n",
    "        self.drug_concept_id.series = self.drug_concept_id.series.map(\n",
    "            {\n",
    "                \"Moderna\": 37003518\n",
    "            }\n",
    "        )\n",
    "        self.drug_source_concept_id.series = self.drug_source_concept_id.series.map(\n",
    "            {\n",
    "                \"Moderna\": 37003518\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    @define_drug_exposure\n",
    "    def drug_exposure_4(self):\n",
    "        \"\"\"\n",
    "        Create CDM object for drug_exposure\n",
    "        \"\"\"\n",
    "        self.drug_concept_id.series = self.inputs[\"Vaccinations.csv\"][\"type\"]\n",
    "        self.drug_exposure_end_datetime.series = self.inputs[\"Vaccinations.csv\"][\"date_of_vaccination\"]\n",
    "        self.drug_exposure_start_datetime.series = self.inputs[\"Vaccinations.csv\"][\"date_of_vaccination\"]\n",
    "        self.drug_source_concept_id.series = self.inputs[\"Vaccinations.csv\"][\"type\"]\n",
    "        self.drug_source_value.series = self.inputs[\"Vaccinations.csv\"][\"type\"]\n",
    "        self.person_id.series = self.inputs[\"Vaccinations.csv\"][\"ID\"]\n",
    "        \n",
    "        # --- insert field operations --- \n",
    "        \n",
    "        # --- insert term mapping --- \n",
    "        self.drug_concept_id.series = self.drug_concept_id.series.map(\n",
    "            {\n",
    "                \"Pfizer\": 37003436\n",
    "            }\n",
    "        )\n",
    "        self.drug_source_concept_id.series = self.drug_source_concept_id.series.map(\n",
    "            {\n",
    "                \"Pfizer\": 37003436\n",
    "            }\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-seminar",
   "metadata": {},
   "source": [
    "Loading some inputs.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "iraqi-briefs",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - DataCollection Object Created\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Registering  Blood_Test.csv [<carrot.io.common.DataBrick object at 0x111f1be50>]\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Registering  Demographics.csv [<carrot.io.common.DataBrick object at 0x111fd15b0>]\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Registering  GP_Records.csv [<carrot.io.common.DataBrick object at 0x111fd12e0>]\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Registering  Hospital_Visit.csv [<carrot.io.common.DataBrick object at 0x111f56b80>]\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Registering  Serology.csv [<carrot.io.common.DataBrick object at 0x111f56730>]\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Registering  Symptoms.csv [<carrot.io.common.DataBrick object at 0x11207f070>]\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Registering  Vaccinations.csv [<carrot.io.common.DataBrick object at 0x11207f340>]\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Registering  pks.csv [<carrot.io.common.DataBrick object at 0x115f20340>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<carrot.io.plugins.local.LocalDataCollection at 0x111fd1f40>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import carrot\n",
    "import glob\n",
    "inputs = carrot.tools.load_csv(glob.glob('../data/part1/*'))\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-briefs",
   "metadata": {},
   "source": [
    "A new instances can be created from the created python class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "collectible-hungarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - CommonDataModel (5.3.1) created with co-connect-tools version 0.0.0\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - Running with an DataCollection object\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - Turning on automatic cdm column filling\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - Added condition_occurrence_0 of type condition_occurrence\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - Added condition_occurrence_1 of type condition_occurrence\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - Added condition_occurrence_10 of type condition_occurrence\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - Added condition_occurrence_11 of type condition_occurrence\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - Added condition_occurrence_2 of type condition_occurrence\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - Added condition_occurrence_3 of type condition_occurrence\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - Added condition_occurrence_4 of type condition_occurrence\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - Added condition_occurrence_5 of type condition_occurrence\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - Added condition_occurrence_6 of type condition_occurrence\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - Added condition_occurrence_7 of type condition_occurrence\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - Added condition_occurrence_8 of type condition_occurrence\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - Added condition_occurrence_9 of type condition_occurrence\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - Added drug_exposure_0 of type drug_exposure\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - Added drug_exposure_1 of type drug_exposure\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - Added drug_exposure_2 of type drug_exposure\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - Added drug_exposure_3 of type drug_exposure\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - Added drug_exposure_4 of type drug_exposure\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - Added observation_0 of type observation\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - Added observation_1 of type observation\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - Added observation_2 of type observation\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - Added observation_3 of type observation\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - Added person_0 of type person\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - Added person_1 of type person\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ExampleDataset at 0x115f20f40>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance = ExampleDataset(inputs=inputs)\n",
    "instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "labeled-walker",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - Starting processing in order: ['person', 'condition_occurrence', 'drug_exposure', 'observation']\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - Number of objects to process for each table...\n",
      "{\n",
      "      \"condition_occurrence\": 12,\n",
      "      \"drug_exposure\": 5,\n",
      "      \"observation\": 4,\n",
      "      \"person\": 2\n",
      "}\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - for person: found 2 objects\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - working on person\n",
      "\u001b[32m2022-06-17 15:17:54\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - starting on person_0\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Retrieving initial dataframe for 'Demographics.csv' for the first time\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mPerson\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in gender_concept_id removed 438 rows, leaving 562 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mPerson\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in birth_datetime removed 1 rows, leaving 561 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mPerson\u001b[0m - \u001b[1;37mINFO\u001b[0m - Automatically formatting data columns.\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mPerson\u001b[0m - \u001b[1;37mINFO\u001b[0m - created df (0x115fa5310)[person_0]\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished person_0 (0x115fa5310) ... 1/2 completed, 561 rows\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - starting on person_1\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mPerson\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in gender_concept_id removed 565 rows, leaving 435 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mPerson\u001b[0m - \u001b[1;37mINFO\u001b[0m - Automatically formatting data columns.\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mPerson\u001b[0m - \u001b[1;37mINFO\u001b[0m - created df (0x115fec4f0)[person_1]\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished person_1 (0x115fec4f0) ... 2/2 completed, 435 rows\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - called save_dateframe but outputs are not defined. save_files: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not convert string to float: 'na'\n",
      "could not convert string to float: 'na'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - finalised person on iteration 0 producing 996 rows from 2 tables\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Getting next chunk of data\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - All input files for this object have now been used.\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - resetting used bricks\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - for condition_occurrence: found 12 objects\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - working on condition_occurrence\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - starting on condition_occurrence_0\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Retrieving initial dataframe for 'Symptoms.csv' for the first time\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in condition_concept_id removed 55 rows, leaving 275 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in condition_start_datetime removed 1 rows, leaving 274 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mINFO\u001b[0m - Automatically formatting data columns.\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mINFO\u001b[0m - created df (0x115fec340)[condition_occurrence_0]\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished condition_occurrence_0 (0x115fec340) ... 1/12 completed, 274 rows\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - starting on condition_occurrence_1\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in condition_concept_id removed 95 rows, leaving 235 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in condition_start_datetime removed 1 rows, leaving 234 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mINFO\u001b[0m - Automatically formatting data columns.\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mINFO\u001b[0m - created df (0x11603e5b0)[condition_occurrence_1]\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished condition_occurrence_1 (0x11603e5b0) ... 2/12 completed, 234 rows\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - starting on condition_occurrence_10\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Retrieving initial dataframe for 'GP_Records.csv' for the first time\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in condition_concept_id removed 1738 rows, leaving 214 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mINFO\u001b[0m - Automatically formatting data columns.\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mINFO\u001b[0m - created df (0x11628fd30)[condition_occurrence_10]\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished condition_occurrence_10 (0x11628fd30) ... 3/12 completed, 214 rows\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mThere are person_ids in this table that are not in the output person table!\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mEither they are not in the original data, or while creating the person table, \u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mstudies have been removed due to lack of required fields, such as birthdate.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31m213/214 were good, 1 studies are removed.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - starting on condition_occurrence_11\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in condition_concept_id removed 1822 rows, leaving 130 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mINFO\u001b[0m - Automatically formatting data columns.\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mINFO\u001b[0m - created df (0x1162a1c70)[condition_occurrence_11]\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished condition_occurrence_11 (0x1162a1c70) ... 4/12 completed, 130 rows\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - starting on condition_occurrence_2\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in condition_concept_id removed 195 rows, leaving 135 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in condition_start_datetime removed 1 rows, leaving 134 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mINFO\u001b[0m - Automatically formatting data columns.\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mINFO\u001b[0m - created df (0x11601b5b0)[condition_occurrence_2]\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished condition_occurrence_2 (0x11601b5b0) ... 5/12 completed, 134 rows\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - starting on condition_occurrence_3\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in condition_concept_id removed 100 rows, leaving 230 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in condition_start_datetime removed 1 rows, leaving 229 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mINFO\u001b[0m - Automatically formatting data columns.\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mINFO\u001b[0m - created df (0x1162b97f0)[condition_occurrence_3]\n",
      "\u001b[32m2022-06-17 15:17:55\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished condition_occurrence_3 (0x1162b97f0) ... 6/12 completed, 229 rows\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - starting on condition_occurrence_4\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in condition_concept_id removed 265 rows, leaving 65 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mINFO\u001b[0m - Automatically formatting data columns.\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mINFO\u001b[0m - created df (0x1162a11f0)[condition_occurrence_4]\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished condition_occurrence_4 (0x1162a11f0) ... 7/12 completed, 65 rows\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - starting on condition_occurrence_5\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in condition_concept_id removed 295 rows, leaving 35 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in condition_start_datetime removed 1 rows, leaving 34 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mINFO\u001b[0m - Automatically formatting data columns.\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mINFO\u001b[0m - created df (0x1162f20a0)[condition_occurrence_5]\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished condition_occurrence_5 (0x1162f20a0) ... 8/12 completed, 34 rows\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - starting on condition_occurrence_6\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Retrieving initial dataframe for 'Hospital_Visit.csv' for the first time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in condition_concept_id removed 1029 rows, leaving 171 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mINFO\u001b[0m - Automatically formatting data columns.\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mINFO\u001b[0m - created df (0x1162f2850)[condition_occurrence_6]\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished condition_occurrence_6 (0x1162f2850) ... 9/12 completed, 171 rows\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - starting on condition_occurrence_7\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in condition_concept_id removed 1508 rows, leaving 444 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mINFO\u001b[0m - Automatically formatting data columns.\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mINFO\u001b[0m - created df (0x1162f2c70)[condition_occurrence_7]\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished condition_occurrence_7 (0x1162f2c70) ... 10/12 completed, 444 rows\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mThere are person_ids in this table that are not in the output person table!\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mEither they are not in the original data, or while creating the person table, \u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mstudies have been removed due to lack of required fields, such as birthdate.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31m441/444 were good, 3 studies are removed.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - starting on condition_occurrence_8\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in condition_concept_id removed 1508 rows, leaving 444 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mINFO\u001b[0m - Automatically formatting data columns.\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mINFO\u001b[0m - created df (0x1162d3400)[condition_occurrence_8]\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished condition_occurrence_8 (0x1162d3400) ... 11/12 completed, 444 rows\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mThere are person_ids in this table that are not in the output person table!\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mEither they are not in the original data, or while creating the person table, \u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mstudies have been removed due to lack of required fields, such as birthdate.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31m441/444 were good, 3 studies are removed.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - starting on condition_occurrence_9\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in condition_concept_id removed 1688 rows, leaving 264 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mINFO\u001b[0m - Automatically formatting data columns.\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mConditionOccurrence\u001b[0m - \u001b[1;37mINFO\u001b[0m - created df (0x116322ca0)[condition_occurrence_9]\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished condition_occurrence_9 (0x116322ca0) ... 12/12 completed, 264 rows\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mRemoved 2 row(s) due to duplicates found when merging condition_occurrence\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mExample duplicates...\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33m                         person_id  condition_concept_id condition_start_date  \\\n",
      "condition_occurrence_id                                                         \n",
      "38                           125.0                378253           2020-04-11   \n",
      "40                           125.0                378253           2020-04-11   \n",
      "308                          125.0               4223659           2020-04-11   \n",
      "310                          125.0               4223659           2020-04-11   \n",
      "\n",
      "                           condition_start_datetime condition_end_date  \\\n",
      "condition_occurrence_id                                                  \n",
      "38                       2020-04-11 00:00:00.000000         2020-04-11   \n",
      "40                       2020-04-11 00:00:00.000000         2020-04-11   \n",
      "308                      2020-04-11 00:00:00.000000         2020-04-11   \n",
      "310                      2020-04-11 00:00:00.000000         2020-04-11   \n",
      "\n",
      "                             condition_end_datetime condition_source_value  \\\n",
      "condition_occurrence_id                                                      \n",
      "38                       2020-04-11 00:00:00.000000                    Yes   \n",
      "40                       2020-04-11 00:00:00.000000                    Yes   \n",
      "308                      2020-04-11 00:00:00.000000                    Yes   \n",
      "310                      2020-04-11 00:00:00.000000                    Yes   \n",
      "\n",
      "                         condition_source_concept_id  \n",
      "condition_occurrence_id                               \n",
      "38                                            378253  \n",
      "40                                            378253  \n",
      "308                                          4223659  \n",
      "310                                          4223659  \u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - called save_dateframe but outputs are not defined. save_files: True\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - finalised condition_occurrence on iteration 0 producing 2630 rows from 12 tables\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Getting next chunk of data\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - All input files for this object have now been used.\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - resetting used bricks\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - for drug_exposure: found 5 objects\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - working on drug_exposure\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - starting on drug_exposure_0\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Retrieving initial dataframe for 'Vaccinations.csv' for the first time\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mDrugExposure\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in drug_concept_id removed 475 rows, leaving 245 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mDrugExposure\u001b[0m - \u001b[1;37mINFO\u001b[0m - Automatically formatting data columns.\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mDrugExposure\u001b[0m - \u001b[1;37mINFO\u001b[0m - created df (0x1163222b0)[drug_exposure_0]\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished drug_exposure_0 (0x1163222b0) ... 1/5 completed, 245 rows\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - starting on drug_exposure_1\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mDrugExposure\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in drug_concept_id removed 494 rows, leaving 226 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mDrugExposure\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in drug_exposure_start_datetime removed 1 rows, leaving 225 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mDrugExposure\u001b[0m - \u001b[1;37mINFO\u001b[0m - Automatically formatting data columns.\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mDrugExposure\u001b[0m - \u001b[1;37mINFO\u001b[0m - created df (0x11634ab20)[drug_exposure_1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished drug_exposure_1 (0x11634ab20) ... 2/5 completed, 225 rows\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mThere are person_ids in this table that are not in the output person table!\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mEither they are not in the original data, or while creating the person table, \u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mstudies have been removed due to lack of required fields, such as birthdate.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:56\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31m224/225 were good, 1 studies are removed.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - starting on drug_exposure_2\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mDrugExposure\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in drug_concept_id removed 471 rows, leaving 249 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mDrugExposure\u001b[0m - \u001b[1;37mINFO\u001b[0m - Automatically formatting data columns.\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mDrugExposure\u001b[0m - \u001b[1;37mINFO\u001b[0m - created df (0x1163752e0)[drug_exposure_2]\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished drug_exposure_2 (0x1163752e0) ... 3/5 completed, 249 rows\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mThere are person_ids in this table that are not in the output person table!\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mEither they are not in the original data, or while creating the person table, \u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mstudies have been removed due to lack of required fields, such as birthdate.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31m248/249 were good, 1 studies are removed.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - starting on drug_exposure_3\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mDrugExposure\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in drug_concept_id removed 475 rows, leaving 245 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mDrugExposure\u001b[0m - \u001b[1;37mINFO\u001b[0m - Automatically formatting data columns.\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mDrugExposure\u001b[0m - \u001b[1;37mINFO\u001b[0m - created df (0x116375700)[drug_exposure_3]\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished drug_exposure_3 (0x116375700) ... 4/5 completed, 245 rows\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - starting on drug_exposure_4\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mDrugExposure\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in drug_concept_id removed 471 rows, leaving 249 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mDrugExposure\u001b[0m - \u001b[1;37mINFO\u001b[0m - Automatically formatting data columns.\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mDrugExposure\u001b[0m - \u001b[1;37mINFO\u001b[0m - created df (0x1163b6610)[drug_exposure_4]\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished drug_exposure_4 (0x1163b6610) ... 5/5 completed, 249 rows\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mThere are person_ids in this table that are not in the output person table!\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mEither they are not in the original data, or while creating the person table, \u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mstudies have been removed due to lack of required fields, such as birthdate.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31m248/249 were good, 1 studies are removed.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - called save_dateframe but outputs are not defined. save_files: True\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - finalised drug_exposure on iteration 0 producing 1210 rows from 5 tables\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Getting next chunk of data\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - All input files for this object have now been used.\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - resetting used bricks\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - for observation: found 4 objects\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - working on observation\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - starting on observation_0\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Retrieving initial dataframe for 'Serology.csv' for the first time\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mObservation\u001b[0m - \u001b[1;37mINFO\u001b[0m - Automatically formatting data columns.\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mObservation\u001b[0m - \u001b[1;37mINFO\u001b[0m - created df (0x1163e8ee0)[observation_0]\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished observation_0 (0x1163e8ee0) ... 1/4 completed, 413 rows\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mThere are person_ids in this table that are not in the output person table!\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mEither they are not in the original data, or while creating the person table, \u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mstudies have been removed due to lack of required fields, such as birthdate.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31m410/413 were good, 3 studies are removed.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - starting on observation_1\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Retrieving initial dataframe for 'Hospital_Visit.csv' for the first time\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mObservation\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in observation_concept_id removed 937 rows, leaving 263 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mObservation\u001b[0m - \u001b[1;37mINFO\u001b[0m - Automatically formatting data columns.\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mObservation\u001b[0m - \u001b[1;37mINFO\u001b[0m - created df (0x1163e8e20)[observation_1]\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished observation_1 (0x1163e8e20) ... 2/4 completed, 263 rows\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mThere are person_ids in this table that are not in the output person table!\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mEither they are not in the original data, or while creating the person table, \u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mstudies have been removed due to lack of required fields, such as birthdate.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31m262/263 were good, 1 studies are removed.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - starting on observation_2\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mObservation\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in observation_concept_id removed 1023 rows, leaving 177 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mObservation\u001b[0m - \u001b[1;37mINFO\u001b[0m - Automatically formatting data columns.\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mObservation\u001b[0m - \u001b[1;37mINFO\u001b[0m - created df (0x116429dc0)[observation_2]\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished observation_2 (0x116429dc0) ... 3/4 completed, 177 rows\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mThere are person_ids in this table that are not in the output person table!\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mEither they are not in the original data, or while creating the person table, \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mstudies have been removed due to lack of required fields, such as birthdate.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31m176/177 were good, 1 studies are removed.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - starting on observation_3\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mObservation\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in observation_concept_id removed 851 rows, leaving 349 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mObservation\u001b[0m - \u001b[1;37mINFO\u001b[0m - Automatically formatting data columns.\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mObservation\u001b[0m - \u001b[1;37mINFO\u001b[0m - created df (0x111fd1d00)[observation_3]\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished observation_3 (0x111fd1d00) ... 4/4 completed, 349 rows\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mRemoved 1 row(s) due to duplicates found when merging observation\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mExample duplicates...\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33m                person_id  observation_concept_id observation_date  \\\n",
      "observation_id                                                       \n",
      "440                 110.0                 4059317       2019-07-07   \n",
      "441                 110.0                 4059317       2019-07-07   \n",
      "\n",
      "                      observation_datetime observation_source_value  \\\n",
      "observation_id                                                        \n",
      "440             2019-07-07 00:00:00.000000             Heart Attack   \n",
      "441             2019-07-07 00:00:00.000000             Heart Attack   \n",
      "\n",
      "                observation_source_concept_id  \n",
      "observation_id                                 \n",
      "440                                   4059317  \n",
      "441                                   4059317  \u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - called save_dateframe but outputs are not defined. save_files: True\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDataset\u001b[0m - \u001b[1;37mINFO\u001b[0m - finalised observation on iteration 0 producing 1197 rows from 4 tables\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Getting next chunk of data\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - All input files for this object have now been used.\n"
     ]
    }
   ],
   "source": [
    "instance.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "inclusive-bubble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['person', 'condition_occurrence', 'drug_exposure', 'observation'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "armed-elder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>observation_concept_id</th>\n",
       "      <th>observation_date</th>\n",
       "      <th>observation_datetime</th>\n",
       "      <th>observation_source_value</th>\n",
       "      <th>observation_source_concept_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>observation_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>357</td>\n",
       "      <td>4288455</td>\n",
       "      <td>2020-10-03</td>\n",
       "      <td>2020-10-03 00:00:00.000000</td>\n",
       "      <td>17.172114692899758</td>\n",
       "      <td>4288455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>258</td>\n",
       "      <td>4288455</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>2020-11-02 00:00:00.000000</td>\n",
       "      <td>201.93861878809216</td>\n",
       "      <td>4288455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>556</td>\n",
       "      <td>4288455</td>\n",
       "      <td>2021-07-26</td>\n",
       "      <td>2021-07-26 00:00:00.000000</td>\n",
       "      <td>11.506250956970998</td>\n",
       "      <td>4288455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>380</td>\n",
       "      <td>4288455</td>\n",
       "      <td>2021-10-29</td>\n",
       "      <td>2021-10-29 00:00:00.000000</td>\n",
       "      <td>2.6594057121417487</td>\n",
       "      <td>4288455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>415</td>\n",
       "      <td>4288455</td>\n",
       "      <td>2021-09-07</td>\n",
       "      <td>2021-09-07 00:00:00.000000</td>\n",
       "      <td>40.844873593089126</td>\n",
       "      <td>4288455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>988</td>\n",
       "      <td>40757663</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>2020-07-21 00:00:00.000000</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>40757663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>555</td>\n",
       "      <td>40757663</td>\n",
       "      <td>2020-10-03</td>\n",
       "      <td>2020-10-03 00:00:00.000000</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>40757663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>992</td>\n",
       "      <td>40757663</td>\n",
       "      <td>2021-06-20</td>\n",
       "      <td>2021-06-20 00:00:00.000000</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>40757663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>992</td>\n",
       "      <td>40757663</td>\n",
       "      <td>2019-05-13</td>\n",
       "      <td>2019-05-13 00:00:00.000000</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>40757663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>992</td>\n",
       "      <td>40757663</td>\n",
       "      <td>2019-08-25</td>\n",
       "      <td>2019-08-25 00:00:00.000000</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>40757663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1196 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                person_id  observation_concept_id observation_date  \\\n",
       "observation_id                                                       \n",
       "1                     357                 4288455       2020-10-03   \n",
       "2                     258                 4288455       2020-11-02   \n",
       "4                     556                 4288455       2021-07-26   \n",
       "5                     380                 4288455       2021-10-29   \n",
       "6                     415                 4288455       2021-09-07   \n",
       "...                   ...                     ...              ...   \n",
       "1193                  988                40757663       2020-07-21   \n",
       "1194                  555                40757663       2020-10-03   \n",
       "1195                  992                40757663       2021-06-20   \n",
       "1196                  992                40757663       2019-05-13   \n",
       "1197                  992                40757663       2019-08-25   \n",
       "\n",
       "                      observation_datetime observation_source_value  \\\n",
       "observation_id                                                        \n",
       "1               2020-10-03 00:00:00.000000       17.172114692899758   \n",
       "2               2020-11-02 00:00:00.000000       201.93861878809216   \n",
       "4               2021-07-26 00:00:00.000000       11.506250956970998   \n",
       "5               2021-10-29 00:00:00.000000       2.6594057121417487   \n",
       "6               2021-09-07 00:00:00.000000       40.844873593089126   \n",
       "...                                    ...                      ...   \n",
       "1193            2020-07-21 00:00:00.000000                   Cancer   \n",
       "1194            2020-10-03 00:00:00.000000                   Cancer   \n",
       "1195            2021-06-20 00:00:00.000000                   Cancer   \n",
       "1196            2019-05-13 00:00:00.000000                   Cancer   \n",
       "1197            2019-08-25 00:00:00.000000                   Cancer   \n",
       "\n",
       "                observation_source_concept_id  \n",
       "observation_id                                 \n",
       "1                                     4288455  \n",
       "2                                     4288455  \n",
       "4                                     4288455  \n",
       "5                                     4288455  \n",
       "6                                     4288455  \n",
       "...                                       ...  \n",
       "1193                                 40757663  \n",
       "1194                                 40757663  \n",
       "1195                                 40757663  \n",
       "1196                                 40757663  \n",
       "1197                                 40757663  \n",
       "\n",
       "[1196 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance['observation'].dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-accessory",
   "metadata": {},
   "source": [
    "## Manually edited \n",
    "\n",
    "By generating a python class from the rules files, you can manually edit the python file setting up i/o as well as making some edits to the various tables. Once done, it could simple be run as a python file:\n",
    "```\n",
    "python  ExampleDatasetModified.py\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "visible-metabolism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ExampleDatasetModified.py\n",
    "from carrot.cdm import define_person, define_condition_occurrence, define_visit_occurrence, define_measurement, define_observation, define_drug_exposure\n",
    "from carrot.cdm import CommonDataModel\n",
    "from carrot.tools import load_csv,create_csv_store\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "class ExampleDatasetModified(CommonDataModel):\n",
    "    \n",
    "    def __init__(self,**kwargs):\n",
    "        \"\"\" \n",
    "        initialise the inputs and setup indexing \n",
    "        \"\"\"\n",
    "        inputs = load_csv(glob.glob('../data/part1/*'))\n",
    "        outputs = create_csv_store(output_folder=\"./data_tests/\",\n",
    "                                                   sep=\"\\t\",\n",
    "                                                   write_separate=True,\n",
    "                                                   write_mode='w')\n",
    "        \n",
    "        super().__init__(inputs=inputs,outputs=outputs,**kwargs)\n",
    "        self.process()\n",
    "    \n",
    "    @define_person\n",
    "    def person_0(self):\n",
    "        \"\"\"\n",
    "        Create CDM object for person\n",
    "        \"\"\"\n",
    "        self.birth_datetime.series = self.inputs[\"Demographics.csv\"][\"Age\"]\n",
    "        self.gender_concept_id.series = self.inputs[\"Demographics.csv\"][\"Sex\"]\n",
    "        self.gender_source_concept_id.series = self.inputs[\"Demographics.csv\"][\"Sex\"]\n",
    "        self.gender_source_value.series = self.inputs[\"Demographics.csv\"][\"Sex\"]\n",
    "        self.person_id.series = self.inputs[\"Demographics.csv\"][\"ID\"]\n",
    "        \n",
    "        # --- insert field operations --- \n",
    "        self.birth_datetime.series = self.tools.get_datetime_from_age(self.birth_datetime.series)\n",
    "        \n",
    "        # --- insert term mapping --- \n",
    "        self.gender_concept_id.series = self.gender_concept_id.series.map(\n",
    "            {\n",
    "                \"Male\": 8507,\n",
    "                \"Female\": 8532\n",
    "            }\n",
    "        )\n",
    "\n",
    "    @define_observation\n",
    "    def observation_0(self):\n",
    "        \"\"\"\n",
    "        Create CDM object for observation\n",
    "        \"\"\"\n",
    "\n",
    "        def convert_igg(x):\n",
    "            \"\"\"\n",
    "            A custom function to convert the IgG into g/L\n",
    "            \"\"\"\n",
    "            try:\n",
    "                igg = float(x['IgG'])\n",
    "            except:\n",
    "                return None\n",
    "            #example of a dataset where the assay has been recalibrated after a certain date\n",
    "            #therefore you might need to do some conversion based upon the date\n",
    "            factor = 1.2 if x['Date'].year < 2021 else 1\n",
    "            \n",
    "            #apply a factor to convert to g/L\n",
    "            factor = factor * 10\n",
    "            \n",
    "            #return the modified IgG value\n",
    "            return igg*factor\n",
    "        \n",
    "        #save the source value of the IgG\n",
    "        self.observation_source_value.series = self.inputs[\"Serology.csv\"][\"IgG\"]\n",
    "\n",
    "        #convert the date into a datetime object\n",
    "        self.inputs[\"Serology.csv\"][\"Date\"] =  pd.to_datetime(self.inputs[\"Serology.csv\"][\"Date\"],\n",
    "                                                             errors='coerce')\n",
    "        \n",
    "        #recalculate the IgG based upon a custom function\n",
    "        self.inputs[\"Serology.csv\"][\"IgG\"] = self.inputs[\"Serology.csv\"].apply(\n",
    "                                                            lambda x: convert_igg(x),axis=1)\n",
    "        #set the output units\n",
    "        self.inputs[\"Serology.csv\"][\"Units\"] = 'g/L'\n",
    "        \n",
    "        #set additional columns we did not have before...\n",
    "        self.unit_source_value.series = self.inputs[\"Serology.csv\"][\"Units\"]\n",
    "        self.value_as_number.series = self.inputs[\"Serology.csv\"][\"IgG\"]\n",
    "\n",
    "        \n",
    "        self.observation_concept_id.series = self.inputs[\"Serology.csv\"][\"IgG\"]\n",
    "        self.observation_datetime.series = self.inputs[\"Serology.csv\"][\"Date\"]\n",
    "        self.observation_source_concept_id.series = self.inputs[\"Serology.csv\"][\"IgG\"]\n",
    "        self.person_id.series = self.inputs[\"Serology.csv\"][\"ID\"]\n",
    "\n",
    "        \n",
    "        # --- insert term mapping --- \n",
    "        self.observation_concept_id.series = self.tools.make_scalar(self.observation_concept_id.series,4288455)\n",
    "        self.observation_source_concept_id.series = self.tools.make_scalar(self.observation_source_concept_id.series,4288455)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "balanced-viking",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - DataCollection Object Created\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Registering  Blood_Test.csv [<carrot.io.common.DataBrick object at 0x116322730>]\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Registering  Demographics.csv [<carrot.io.common.DataBrick object at 0x111f1ba90>]\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Registering  GP_Records.csv [<carrot.io.common.DataBrick object at 0x111f56d60>]\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Registering  Hospital_Visit.csv [<carrot.io.common.DataBrick object at 0x111f56c10>]\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Registering  Serology.csv [<carrot.io.common.DataBrick object at 0x116458a00>]\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Registering  Symptoms.csv [<carrot.io.common.DataBrick object at 0x116458f40>]\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Registering  Vaccinations.csv [<carrot.io.common.DataBrick object at 0x1163e86a0>]\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Registering  pks.csv [<carrot.io.common.DataBrick object at 0x1163e8b80>]\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - DataCollection Object Created\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDatasetModified\u001b[0m - \u001b[1;37mINFO\u001b[0m - CommonDataModel (5.3.1) created with co-connect-tools version 0.0.0\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDatasetModified\u001b[0m - \u001b[1;37mINFO\u001b[0m - Running with an DataCollection object\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDatasetModified\u001b[0m - \u001b[1;37mINFO\u001b[0m - Turning on automatic cdm column filling\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDatasetModified\u001b[0m - \u001b[1;37mINFO\u001b[0m - Added observation_0 of type observation\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDatasetModified\u001b[0m - \u001b[1;37mINFO\u001b[0m - Added person_0 of type person\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDatasetModified\u001b[0m - \u001b[1;37mINFO\u001b[0m - Starting processing in order: ['person', 'observation']\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDatasetModified\u001b[0m - \u001b[1;37mINFO\u001b[0m - Number of objects to process for each table...\n",
      "{\n",
      "      \"observation\": 1,\n",
      "      \"person\": 1\n",
      "}\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDatasetModified\u001b[0m - \u001b[1;37mINFO\u001b[0m - for person: found 1 object\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDatasetModified\u001b[0m - \u001b[1;37mINFO\u001b[0m - working on person\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mExampleDatasetModified\u001b[0m - \u001b[1;37mINFO\u001b[0m - starting on person_0\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Retrieving initial dataframe for 'Demographics.csv' for the first time\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mPerson\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in gender_concept_id removed 3 rows, leaving 997 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mPerson\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in birth_datetime removed 1 rows, leaving 996 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:57\u001b[0m - \u001b[34mPerson\u001b[0m - \u001b[1;37mINFO\u001b[0m - Automatically formatting data columns.\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mPerson\u001b[0m - \u001b[1;37mINFO\u001b[0m - created df (0x11654bcd0)[person_0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not convert string to float: 'na'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mExampleDatasetModified\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished person_0 (0x11654bcd0) ... 1/1 completed, 996 rows\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - saving person_ids.0x1164a5d30.2022-06-17T141758 to ./data_tests//person_ids.0x1164a5d30.2022-06-17T141758.tsv\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished save to file\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mExampleDatasetModified\u001b[0m - \u001b[1;37mINFO\u001b[0m - saving dataframe (0x1164852e0) to <carrot.io.plugins.local.LocalDataCollection object at 0x1164585e0>\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - saving person.person_0.0x1164852e0.2022-06-17T141758 to ./data_tests//person.person_0.0x1164852e0.2022-06-17T141758.tsv\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished save to file\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mExampleDatasetModified\u001b[0m - \u001b[1;37mINFO\u001b[0m - finalised person on iteration 0 producing 996 rows from 1 tables\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Getting next chunk of data\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - All input files for this object have now been used.\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - resetting used bricks\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mExampleDatasetModified\u001b[0m - \u001b[1;37mINFO\u001b[0m - for observation: found 1 object\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mExampleDatasetModified\u001b[0m - \u001b[1;37mINFO\u001b[0m - working on observation\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mExampleDatasetModified\u001b[0m - \u001b[1;37mINFO\u001b[0m - starting on observation_0\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Retrieving initial dataframe for 'Serology.csv' for the first time\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mObservation\u001b[0m - \u001b[1;37mWARNING\u001b[0m - \u001b[33mRequiring non-null values in observation_datetime removed 2 rows, leaving 413 rows.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mObservation\u001b[0m - \u001b[1;37mINFO\u001b[0m - Automatically formatting data columns.\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mObservation\u001b[0m - \u001b[1;37mINFO\u001b[0m - created df (0x1164a5af0)[observation_0]\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mExampleDatasetModified\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished observation_0 (0x1164a5af0) ... 1/1 completed, 413 rows\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mExampleDatasetModified\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mThere are person_ids in this table that are not in the output person table!\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mExampleDatasetModified\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mEither they are not in the original data, or while creating the person table, \u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mExampleDatasetModified\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31mstudies have been removed due to lack of required fields, such as birthdate.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mExampleDatasetModified\u001b[0m - \u001b[1;37mERROR\u001b[0m - \u001b[31m410/413 were good, 3 studies are removed.\u001b[0m\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mExampleDatasetModified\u001b[0m - \u001b[1;37mINFO\u001b[0m - saving dataframe (0x11659e9d0) to <carrot.io.plugins.local.LocalDataCollection object at 0x1164585e0>\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - saving observation.observation_0.0x11659e9d0.2022-06-17T141758 to ./data_tests//observation.observation_0.0x11659e9d0.2022-06-17T141758.tsv\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - finished save to file\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mExampleDatasetModified\u001b[0m - \u001b[1;37mINFO\u001b[0m - finalised observation on iteration 0 producing 410 rows from 1 tables\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - Getting next chunk of data\n",
      "\u001b[32m2022-06-17 15:17:58\u001b[0m - \u001b[34mLocalDataCollection\u001b[0m - \u001b[1;37mINFO\u001b[0m - All input files for this object have now been used.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ExampleDatasetModified at 0x116458b20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance = ExampleDatasetModified()\n",
    "instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "simple-cleveland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['person', 'observation'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fifteen-parcel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>observation_concept_id</th>\n",
       "      <th>observation_date</th>\n",
       "      <th>observation_datetime</th>\n",
       "      <th>observation_source_value</th>\n",
       "      <th>observation_source_concept_id</th>\n",
       "      <th>unit_source_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>observation_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>650</td>\n",
       "      <td>4288455</td>\n",
       "      <td>2020-10-03</td>\n",
       "      <td>2020-10-03 00:00:00.000000</td>\n",
       "      <td>17.172114692899758</td>\n",
       "      <td>4288455</td>\n",
       "      <td>g/L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>457</td>\n",
       "      <td>4288455</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>2020-11-02 00:00:00.000000</td>\n",
       "      <td>201.93861878809216</td>\n",
       "      <td>4288455</td>\n",
       "      <td>g/L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>983</td>\n",
       "      <td>4288455</td>\n",
       "      <td>2021-07-26</td>\n",
       "      <td>2021-07-26 00:00:00.000000</td>\n",
       "      <td>11.506250956970998</td>\n",
       "      <td>4288455</td>\n",
       "      <td>g/L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>696</td>\n",
       "      <td>4288455</td>\n",
       "      <td>2021-10-29</td>\n",
       "      <td>2021-10-29 00:00:00.000000</td>\n",
       "      <td>2.6594057121417487</td>\n",
       "      <td>4288455</td>\n",
       "      <td>g/L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>751</td>\n",
       "      <td>4288455</td>\n",
       "      <td>2021-09-07</td>\n",
       "      <td>2021-09-07 00:00:00.000000</td>\n",
       "      <td>40.844873593089126</td>\n",
       "      <td>4288455</td>\n",
       "      <td>g/L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>187</td>\n",
       "      <td>4288455</td>\n",
       "      <td>2022-11-07</td>\n",
       "      <td>2022-11-07 00:00:00.000000</td>\n",
       "      <td>51.77573831029082</td>\n",
       "      <td>4288455</td>\n",
       "      <td>g/L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>886</td>\n",
       "      <td>4288455</td>\n",
       "      <td>2022-09-07</td>\n",
       "      <td>2022-09-07 00:00:00.000000</td>\n",
       "      <td>57.11515081936336</td>\n",
       "      <td>4288455</td>\n",
       "      <td>g/L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>50</td>\n",
       "      <td>4288455</td>\n",
       "      <td>2022-11-07</td>\n",
       "      <td>2022-11-07 00:00:00.000000</td>\n",
       "      <td>15.264660709568151</td>\n",
       "      <td>4288455</td>\n",
       "      <td>g/L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>260</td>\n",
       "      <td>4288455</td>\n",
       "      <td>2019-11-13</td>\n",
       "      <td>2019-11-13 00:00:00.000000</td>\n",
       "      <td>26.051354325968106</td>\n",
       "      <td>4288455</td>\n",
       "      <td>g/L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>370</td>\n",
       "      <td>4288455</td>\n",
       "      <td>2020-05-25</td>\n",
       "      <td>2020-05-25 00:00:00.000000</td>\n",
       "      <td>4.266438928364172</td>\n",
       "      <td>4288455</td>\n",
       "      <td>g/L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                person_id  observation_concept_id observation_date  \\\n",
       "observation_id                                                       \n",
       "1                     650                 4288455       2020-10-03   \n",
       "2                     457                 4288455       2020-11-02   \n",
       "3                     983                 4288455       2021-07-26   \n",
       "4                     696                 4288455       2021-10-29   \n",
       "5                     751                 4288455       2021-09-07   \n",
       "...                   ...                     ...              ...   \n",
       "409                   187                 4288455       2022-11-07   \n",
       "410                   886                 4288455       2022-09-07   \n",
       "411                    50                 4288455       2022-11-07   \n",
       "412                   260                 4288455       2019-11-13   \n",
       "413                   370                 4288455       2020-05-25   \n",
       "\n",
       "                      observation_datetime observation_source_value  \\\n",
       "observation_id                                                        \n",
       "1               2020-10-03 00:00:00.000000       17.172114692899758   \n",
       "2               2020-11-02 00:00:00.000000       201.93861878809216   \n",
       "3               2021-07-26 00:00:00.000000       11.506250956970998   \n",
       "4               2021-10-29 00:00:00.000000       2.6594057121417487   \n",
       "5               2021-09-07 00:00:00.000000       40.844873593089126   \n",
       "...                                    ...                      ...   \n",
       "409             2022-11-07 00:00:00.000000        51.77573831029082   \n",
       "410             2022-09-07 00:00:00.000000        57.11515081936336   \n",
       "411             2022-11-07 00:00:00.000000       15.264660709568151   \n",
       "412             2019-11-13 00:00:00.000000       26.051354325968106   \n",
       "413             2020-05-25 00:00:00.000000        4.266438928364172   \n",
       "\n",
       "                observation_source_concept_id unit_source_value  \n",
       "observation_id                                                   \n",
       "1                                     4288455               g/L  \n",
       "2                                     4288455               g/L  \n",
       "3                                     4288455               g/L  \n",
       "4                                     4288455               g/L  \n",
       "5                                     4288455               g/L  \n",
       "...                                       ...               ...  \n",
       "409                                   4288455               g/L  \n",
       "410                                   4288455               g/L  \n",
       "411                                   4288455               g/L  \n",
       "412                                   4288455               g/L  \n",
       "413                                   4288455               g/L  \n",
       "\n",
       "[410 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance['observation'].dropna(axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
