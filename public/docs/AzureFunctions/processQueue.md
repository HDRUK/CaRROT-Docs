## Introduction
**ProcessQueue** refers to the Azure QueueTrigger function which executes  when a new message appears in the Scan Report queue. A new message is added to the queue when a Scan Report file is uploaded from the user. This triggers the ProcessQueue function which processes the data from the excel file and saves it in the database.

## Triggering the function
When a White Rabbit Scan Report file is uploaded on the site, it is saved into Azure Blob Storage and a message is send to the storage Queue. This message includes the `scan_report_id` from the `ScanReport` model and `blob_name` which is the name of the uploaded file. The queue message needs to be encoded before being sent to the queue for the ProcessQueue to access it correctly.
```python
 azure_dict={
            "scan_report_id":scan_report.id,
            "blob_name":str(scan_report.file)
        }
        
        queue_message=json.dumps(azure_dict)
        message_bytes = queue_message.encode('ascii')
        base64_bytes = base64.b64encode(message_bytes)
        base64_message = base64_bytes.decode('ascii')
        
        queue = QueueClient.from_connection_string(
            conn_str=<connection string>,
            queue_name=<queue name>
        )
        queue.send_message(base64_message)
```

![Queue Trigger](images/trigger.png)

**Figure 1** Triggering the Queue when uploading a Scan Report

## Accessing the File
As soon as the ProcessQueue is triggered it uses the `blob_name` from the message body to download the file from Azure Blob Storage into a BytesIO() object.

## Processing
The next step is to step through the Excel workbook and create model entries for each **ScanReportTable**, **ScanReportField** and **ScanReportValue** present in the file.

### Scan Report Table
The **Field Overview** sheet in a White Rabbit Scan Report has a 'Table' column which seperates different table names using a blank row. ProcessQueue main method iterates through the rows in the 'Table' column and appends each unique table name to the list `table_names`. 
For each table in `table_names` a new `ScanReportTable` entry is generated. The table entries are linked to the `ScanReport` model using the `scan_report_id` from the queue message body.
The table entries are then appended to a JSON array `json_data` which forms the input send in a POST request to the [API](API.md).
The API automatically generates the `id` for each table that was created. These ids are extracted from the POST request response and saved in a list (`table_ids`)

### Scan Report Field
**Field Overview** contains all the information on the fields including the name, description and other useful columns. ProcessQueue iterates through the rows in the sheet and generates a new `ScanReportField` entry.
Once it detects an empty line (end of a table) it saves the fields found in that table.
This is done by appending the field entries to a JSON array `json_data`, which forms the input to a POST request made to the [API](API.md). From the response it saves the `field_ids` and `field_names` and stores them into a dictionary as key value pairs e.g "Field Name": Field ID.

### Scan Report Value

Scan report values are stored in sheets named after their corresponding table. Once the fields in a table are saved, it moves to the corresponding sheet (where the sheet is the same as the table_name) and the `process_scan_report_sheet_table()` function is called on that worksheet. The function extracts the data in the following format:

**Input**

 ID  | Frequency    | Date |Frequency
----------| -------------|----------|---------
  1 | 20           | 02/12/2020  |5
  2 | 3            | 12/11/2020 |37

**Output**

(ID, 1, 20)
(Date, 02/12/2020, 5)
(ID, 2, 3)
(Date, 12/11/2020, 37)

A ScanReportValue entry is generated by iterating through the output of `process_scan_report_sheet_table()`. The value entries are linked to the `ScanReportField` model using the function output and the dictionary with all the field names and ids. Same as with the other two models the value entries are appended to a JSON array `json_data`, and form the input to a POST request made to the [API](MappingPipeline/API.md).
